{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_number</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Consommation</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-03-01 01:57:10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-03-01 02:57:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-03-01 03:57:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-03-01 04:57:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-03-01 05:57:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288548</th>\n",
       "      <td>92</td>\n",
       "      <td>2017-02-28 18:08:01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288549</th>\n",
       "      <td>92</td>\n",
       "      <td>2017-02-28 19:08:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288550</th>\n",
       "      <td>92</td>\n",
       "      <td>2017-02-28 20:08:06</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288551</th>\n",
       "      <td>92</td>\n",
       "      <td>2017-02-28 21:08:06</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288552</th>\n",
       "      <td>92</td>\n",
       "      <td>2017-02-28 22:08:06</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288553 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_number             datetime  Consommation  cluster\n",
       "0                 5  2016-03-01 01:57:10             3        2\n",
       "1                 5  2016-03-01 02:57:06             0        2\n",
       "2                 5  2016-03-01 03:57:06             0        2\n",
       "3                 5  2016-03-01 04:57:06             0        2\n",
       "4                 5  2016-03-01 05:57:06             0        2\n",
       "...             ...                  ...           ...      ...\n",
       "288548           92  2017-02-28 18:08:01             0        2\n",
       "288549           92  2017-02-28 19:08:06             0        2\n",
       "288550           92  2017-02-28 20:08:06            27        2\n",
       "288551           92  2017-02-28 21:08:06            43        2\n",
       "288552           92  2017-02-28 22:08:06             5        2\n",
       "\n",
       "[288553 rows x 4 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Load your dataset\n",
    "# Replace 'data.csv' with your actual filename\n",
    "df = pd.read_csv('split_by_clusters/cluster_2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Anomalies (anomalie and type Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'anomalie' column initialized to 0\n",
    "df['anomalie'] = 0\n",
    "df['type'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_number</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Consommation</th>\n",
       "      <th>cluster</th>\n",
       "      <th>anomalie</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-03-01 01:57:10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-03-01 02:57:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-03-01 03:57:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-03-01 04:57:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2016-03-01 05:57:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288548</th>\n",
       "      <td>92</td>\n",
       "      <td>2017-02-28 18:08:01</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288549</th>\n",
       "      <td>92</td>\n",
       "      <td>2017-02-28 19:08:06</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288550</th>\n",
       "      <td>92</td>\n",
       "      <td>2017-02-28 20:08:06</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288551</th>\n",
       "      <td>92</td>\n",
       "      <td>2017-02-28 21:08:06</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288552</th>\n",
       "      <td>92</td>\n",
       "      <td>2017-02-28 22:08:06</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288553 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_number             datetime  Consommation  cluster  anomalie  \\\n",
       "0                 5  2016-03-01 01:57:10             3        2         0   \n",
       "1                 5  2016-03-01 02:57:06             0        2         0   \n",
       "2                 5  2016-03-01 03:57:06             0        2         0   \n",
       "3                 5  2016-03-01 04:57:06             0        2         0   \n",
       "4                 5  2016-03-01 05:57:06             0        2         0   \n",
       "...             ...                  ...           ...      ...       ...   \n",
       "288548           92  2017-02-28 18:08:01             0        2         0   \n",
       "288549           92  2017-02-28 19:08:06             0        2         0   \n",
       "288550           92  2017-02-28 20:08:06            27        2         0   \n",
       "288551           92  2017-02-28 21:08:06            43        2         0   \n",
       "288552           92  2017-02-28 22:08:06             5        2         0   \n",
       "\n",
       "        type  \n",
       "0       None  \n",
       "1       None  \n",
       "2       None  \n",
       "3       None  \n",
       "4       None  \n",
       "...      ...  \n",
       "288548  None  \n",
       "288549  None  \n",
       "288550  None  \n",
       "288551  None  \n",
       "288552  None  \n",
       "\n",
       "[288553 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retour d'eau anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sélectionner l'utilisateur spécifique\n",
    "user_id = 8045\n",
    "\n",
    "# Filtrer les données de l'utilisateur 10\n",
    "user_10 = df[df['user_number'] == user_id]\n",
    "user_10\n",
    "# Créer une copie du DataFrame normal\n",
    "df_anormal = user_10[user_10['anomalie'] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  datetime  Consommation  anomalie                 type\n",
      "156113 2016-08-04 19:27:09          -120         1  prb de retour d/eau\n",
      "156114 2016-08-04 20:27:09          -153         1  prb de retour d/eau\n",
      "156115 2016-08-04 21:27:09           -70         1  prb de retour d/eau\n",
      "156116 2016-08-04 22:27:09           -70         1  prb de retour d/eau\n",
      "156117 2016-08-04 23:27:21           -84         1  prb de retour d/eau\n",
      "...                    ...           ...       ...                  ...\n",
      "158223 2016-01-12 21:24:14          -120         1  prb de retour d/eau\n",
      "158224 2016-01-12 22:24:07           -97         1  prb de retour d/eau\n",
      "158225 2016-01-12 23:24:07           -82         1  prb de retour d/eau\n",
      "159061 2017-12-02 22:24:06          -120         1  prb de retour d/eau\n",
      "159062 2017-12-02 23:24:06           -71         1  prb de retour d/eau\n",
      "\n",
      "[102 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Conversion et nettoyage de la colonne datetime\n",
    "df_anormal['datetime'] = pd.to_datetime(df_anormal['datetime'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Supprimer les lignes avec des dates invalides si nécessaire\n",
    "df_anormal = df_anormal.dropna(subset=['datetime'])\n",
    "\n",
    "# Nombre d'anomalies à ajouter\n",
    "num_anomalies =1\n",
    "\n",
    "# Trouver les indices où la consommation est égale à 50 ou 70\n",
    "anomaly_indices = df_anormal[df_anormal['Consommation'].isin([50, 70])].index\n",
    "\n",
    "# Si le nombre d'anomalies souhaité est supérieur au nombre d'anomalies disponibles, on réduit à la taille disponible\n",
    "num_anomalies = min(num_anomalies, len(anomaly_indices))\n",
    "\n",
    "# Sélectionner aléatoirement les indices où l'on va ajouter des anomalies\n",
    "selected_anomaly_indices = np.random.choice(anomaly_indices, size=num_anomalies, replace=False)\n",
    "\n",
    "# Durée de l'anomalie en jours (par exemple, 2 jours)\n",
    "anomaly_duration = pd.Timedelta(days=1)\n",
    "\n",
    "# Ajouter les anomalies\n",
    "for idx in selected_anomaly_indices:\n",
    "    # Identifier la plage de deux jours autour de l'indice\n",
    "    anomaly_start = df_anormal.loc[idx, 'datetime']\n",
    "    anomaly_end = anomaly_start + anomaly_duration\n",
    "    \n",
    "    # Sélectionner les lignes dans cette plage\n",
    "    anomaly_range = (df_anormal['datetime'] >= anomaly_start) & (df_anormal['datetime'] < anomaly_end)\n",
    "    \n",
    "    # Inverser les valeurs de consommation pour cette plage\n",
    "    df_anormal.loc[anomaly_range, 'Consommation'] = -df_anormal.loc[anomaly_range, 'Consommation']-70\n",
    "    \n",
    "    # Marquer ces lignes comme anomalies et définir le type d'anomalie\n",
    "    df_anormal.loc[anomaly_range, ['anomalie', 'type']] = [1, 'prb de retour d/eau']\n",
    "\n",
    "# Afficher les anomalies ajoutées\n",
    "print(df_anormal[df_anormal['anomalie'] == 1][['datetime', 'Consommation', 'anomalie', 'type']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données modifiées ont été ajoutées et exportées vers 'cluster0_anomalie.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Modifier la colonne user_number dans df_anormal\n",
    "df_anormal['user_number'] = 8045\n",
    "\n",
    "# Ajouter les données modifiées à df2\n",
    "df2 = pd.concat([df, df_anormal], ignore_index=True)\n",
    "\n",
    "# Exporter le DataFrame final vers un fichier CSV\n",
    "df2.to_csv('Fianl2.csv', index=False)  # index=False pour ne pas inclure l'index dans le fichier CSV\n",
    "\n",
    "# Confirmation de l'exportation\n",
    "print(\"Les données modifiées ont été ajoutées et exportées vers 'cluster0_anomalie.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuite de consommation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  datetime  Consommation  anomalie                   type\n",
      "155913 2016-03-12 11:27:31          1021         1        Surconsommation\n",
      "156112 2016-04-08 18:27:11          1021         1        Surconsommation\n",
      "156811 2016-07-02 21:26:13          1090         1        Surconsommation\n",
      "156873 2016-07-05 11:26:08          1046         1        Surconsommation\n",
      "157625 2016-09-12 23:25:09          1010         1        Surconsommation\n",
      "...                    ...           ...       ...                    ...\n",
      "186777 2016-12-07 20:24:16          1501         1  Fuite de consommation\n",
      "186778 2016-12-07 21:24:16          1547         1  Fuite de consommation\n",
      "186779 2016-12-07 22:24:13          1500         1  Fuite de consommation\n",
      "186780 2016-12-07 23:24:13          1537         1  Fuite de consommation\n",
      "187298 2017-02-05 15:23:38          1032         1        Surconsommation\n",
      "\n",
      "[205 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('Final2.csv')  # Remplace par le chemin réel de ton fichier\n",
    "\n",
    "# Sélectionner les données de l'utilisateur 60\n",
    "user_id = 8045\n",
    "user_60 = df[df['user_number'] == user_id].copy()\n",
    "\n",
    "# Convertir la colonne datetime en format datetime si ce n'est pas déjà fait\n",
    "user_60['datetime'] = pd.to_datetime(user_60['datetime'], errors='coerce')\n",
    "user_60['datetime'] = pd.to_datetime(user_60['datetime'], format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
    "\n",
    "\n",
    "# Créer une copie de user_60 pour ajouter l'anomalie (user_60_anomaly)\n",
    "user_60_anomaly = user_60.copy()\n",
    "\n",
    "# Définir les paramètres de l'anomalie\n",
    "anomaly_gap = 1500  # Valeur de la fuite à ajouter\n",
    "\n",
    "# Sélectionner un jour aléatoire parmi les dates disponibles\n",
    "random_date = np.random.choice(user_60['datetime'].dt.date.unique(), size=1, replace=False)[0]\n",
    "\n",
    "# Appliquer l'anomalie pour le jour sélectionné et les deux jours suivants\n",
    "for day_offset in range(0, 3):  # 3 jours successifs\n",
    "    selected_date = random_date + pd.Timedelta(days=day_offset)  # Calculer la date successive\n",
    "    \n",
    "    # Appliquer l'anomalie sur toutes les lignes de ces jours successifs\n",
    "    condition = user_60_anomaly['datetime'].dt.date == selected_date  # Trouver les lignes correspondant à cette date\n",
    "    user_60_anomaly.loc[condition, 'Consommation'] += anomaly_gap  # Ajouter le gap de consommation\n",
    "    user_60_anomaly.loc[condition, 'anomalie'] = 1  # Marquer comme anomalie\n",
    "    user_60_anomaly.loc[condition, 'type'] = 'Fuite de consommation'  # Type d'anomalie\n",
    "\n",
    "# Afficher les anomalies ajoutées\n",
    "\n",
    "anomalies = user_60_anomaly['anomalie'] == 1  # Condition pour filtrer les anomalies\n",
    "print(user_60_anomaly.loc[anomalies, ['datetime', 'Consommation', 'anomalie', 'type']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les données modifiées ont été ajoutées et exportées vers 'Final2.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Modifier la colonne user_number dans df_anormal\n",
    "user_60_anomaly['user_number'] = 8045\n",
    "\n",
    "# Ajouter les données modifiées à df2\n",
    "df2 = pd.concat([df, user_60_anomaly], ignore_index=True)\n",
    "\n",
    "# Exporter le DataFrame final vers un fichier CSV\n",
    "df2.to_csv('Final2.csv', index=False)  # index=False pour ne pas inclure l'index dans le fichier CSV\n",
    "\n",
    "# Confirmation de l'exportation\n",
    "print(\"Les données modifiées ont été ajoutées et exportées vers 'Final2.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prb compteur anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 datetime  Consommation  anomalie             type\n",
      "87808 2016-03-01 13:07:10           -89         1  prb de compteur\n",
      "87830 2016-03-02 19:07:03           -75         1  prb de compteur\n",
      "87939 2016-03-08 00:06:49           -77         1  prb de compteur\n",
      "87998 2016-03-10 23:06:41           -83         1  prb de compteur\n",
      "88120 2016-04-04 01:06:09           -75         1  prb de compteur\n",
      "88153 2016-04-05 10:05:54           -70         1  prb de compteur\n",
      "88295 2016-04-12 00:05:24          -162         1  prb de compteur\n",
      "89503 2016-09-09 13:59:22           -70         1  prb de compteur\n",
      "89898 2016-11-05 12:57:03           -95         1  prb de compteur\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV\n",
    "df = pd.read_csv('Final2.csv')  # Remplace par le chemin réel de ton fichier\n",
    "\n",
    "# Sélectionner l'utilisateur spécifique\n",
    "user_id = 77\n",
    "# Filtrer les données de l'utilisateur spécifique\n",
    "user_10 = df[df['user_number'] == user_id].copy()\n",
    "\n",
    "# Conversion de la colonne datetime en format datetime\n",
    "user_10['datetime'] = pd.to_datetime(user_10['datetime'], errors='coerce')\n",
    "\n",
    "# Créer une copie pour les anomalies\n",
    "df_anormal = user_10.copy()\n",
    "\n",
    "# Fixer la graine pour la reproductibilité\n",
    "np.random.seed(42)\n",
    "\n",
    "# Nettoyage de la colonne datetime\n",
    "df_anormal['datetime'] = pd.to_datetime(df_anormal['datetime'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Supprimer les lignes avec des dates invalides si nécessaire\n",
    "df_anormal = df_anormal.dropna(subset=['datetime'])\n",
    "\n",
    "# Durée de l'anomalie en jours (par exemple, 2 jours)\n",
    "anomaly_duration = pd.Timedelta(days=2)\n",
    "\n",
    "# Nombre d'anomalies à ajouter\n",
    "num_anomalies = 9  # Exemple : 2 anomalies\n",
    "\n",
    "# Trouver les indices où la consommation est élevée\n",
    "anomaly_indices = df_anormal[df_anormal['Consommation'] >= 10].index\n",
    "\n",
    "# Si le nombre d'anomalies souhaité est supérieur au nombre d'anomalies disponibles, on réduit à la taille disponible\n",
    "num_anomalies = min(num_anomalies, len(anomaly_indices))\n",
    "\n",
    "# Sélectionner aléatoirement les indices où l'on va ajouter des anomalies\n",
    "selected_anomaly_indices = np.random.choice(anomaly_indices, size=num_anomalies, replace=False)\n",
    "\n",
    "# Ajouter les anomalies instantanées\n",
    "for idx in selected_anomaly_indices:\n",
    "    # Appliquer un pic négatif instantané\n",
    "    df_anormal.loc[idx, 'Consommation'] = -abs(df_anormal.loc[idx, 'Consommation'])-60\n",
    "    # Marquer cette ligne comme anomalie et définir le type d'anomalie\n",
    "    df_anormal.loc[idx, ['anomalie', 'type']] = [1, 'prb de compteur']\n",
    "\n",
    "# Afficher les anomalies ajoutées\n",
    "print(df_anormal[df_anormal['anomalie'] == 1][['datetime', 'Consommation', 'anomalie', 'type']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifier le numéro d'utilisateur (par exemple, en ajoutant un préfixe ou une valeur différente)\n",
    "df_anormal['user_number'] =1037 # Changer le numéro d'utilisateur pour les données modifiées (par exemple 99999)\n",
    "\n",
    "# Concaténer user_60_anomaly avec le DataFrame d'origine (df)\n",
    "df_combined = pd.concat([ df ,df_anormal ])\n",
    "\n",
    "# Enregistrer le DataFrame combiné dans un fichier CSV\n",
    "df_combined.to_csv('Final2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surconsommation anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  datetime  Consommation  anomalie             type\n",
      "139040 2016-03-05 21:43:20             0         1    Coupure d'eau\n",
      "139041 2016-03-05 22:43:14             0         1    Coupure d'eau\n",
      "139042 2016-03-05 23:43:14             0         1    Coupure d'eau\n",
      "139061 2016-03-07 02:43:15          1162         1  Surconsommation\n",
      "139155 2016-03-12 20:43:07          1013         1  Surconsommation\n",
      "...                    ...           ...       ...              ...\n",
      "180568 2017-02-08 14:50:05             0         1    Coupure d'eau\n",
      "180569 2017-02-08 15:50:05             0         1    Coupure d'eau\n",
      "180570 2017-02-08 16:50:05             0         1    Coupure d'eau\n",
      "180571 2017-02-08 17:50:05             0         1    Coupure d'eau\n",
      "180607 2017-02-11 05:30:57          1010         1  Surconsommation\n",
      "\n",
      "[142 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV\n",
    "df = pd.read_csv('Final2.csv')  # Remplace par le chemin réel de ton fichier\n",
    "\n",
    "# Sélectionner l'utilisateur spécifique\n",
    "user_id =8270\n",
    "# Filtrer les données de l'utilisateur spécifique\n",
    "user_10 = df[df['user_number'] == user_id].copy()\n",
    "\n",
    "# Conversion de la colonne datetime en format datetime\n",
    "user_10['datetime'] = pd.to_datetime(user_10['datetime'], errors='coerce')\n",
    "\n",
    "# Créer une copie pour les anomalies\n",
    "df_anormal = user_10.copy()\n",
    "\n",
    "# Fixer la graine pour la reproductibilité\n",
    "np.random.seed(42)\n",
    "\n",
    "# Nettoyage de la colonne datetime\n",
    "df_anormal['datetime'] = pd.to_datetime(df_anormal['datetime'], errors='coerce', dayfirst=True)\n",
    "\n",
    "# Supprimer les lignes avec des dates invalides si nécessaire\n",
    "df_anormal = df_anormal.dropna(subset=['datetime'])\n",
    "\n",
    "# Durée de l'anomalie en jours (par exemple, 2 jours)\n",
    "anomaly_duration = pd.Timedelta(days=2)\n",
    "\n",
    "# Nombre d'anomalies à ajouter\n",
    "num_anomalies = 9  # Exemple : 2 anomalies\n",
    "\n",
    "# Trouver les indices où la consommation est élevée\n",
    "anomaly_indices = df_anormal[df_anormal['Consommation'] >= 10].index\n",
    "\n",
    "# Si le nombre d'anomalies souhaité est supérieur au nombre d'anomalies disponibles, on réduit à la taille disponible\n",
    "num_anomalies = min(num_anomalies, len(anomaly_indices))\n",
    "\n",
    "# Sélectionner aléatoirement les indices où l'on va ajouter des anomalies\n",
    "selected_anomaly_indices = np.random.choice(anomaly_indices, size=num_anomalies, replace=False)\n",
    "\n",
    "# Ajouter les anomalies instantanées\n",
    "for idx in selected_anomaly_indices:\n",
    "    # Appliquer un pic négatif instantané\n",
    "    df_anormal.loc[idx, 'Consommation'] = abs(df_anormal.loc[idx, 'Consommation'])+1000\n",
    "    # Marquer cette ligne comme anomalie et définir le type d'anomalie\n",
    "    df_anormal.loc[idx, ['anomalie', 'type']] = [1, 'Surconsommation']\n",
    "\n",
    "# Afficher les anomalies ajoutées\n",
    "print(df_anormal[df_anormal['anomalie'] == 1][['datetime', 'Consommation', 'anomalie', 'type']])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifier le numéro d'utilisateur (par exemple, en ajoutant un préfixe ou une valeur différente)\n",
    "df_anormal['user_number'] =340\n",
    "# Changer le numéro d'utilisateur pour les données modifiées (par exemple 99999)\n",
    "\n",
    "# Concaténer user_60_anomaly avec le DataFrame d'origine (df)\n",
    "df_combined = pd.concat([ df ,df_anormal ])\n",
    "\n",
    "# Enregistrer le DataFrame combiné dans un fichier CSV\n",
    "df_combined.to_csv('Final2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
